## ğŸ“– Project Overview Task Sentiment Analyzer is a **machine learning and NLP-based project** that performs sentiment analysis on text data, classifying comments as **Positive** or **Negative**. The project explores multiple models, including traditional machine learning algorithms and deep learning, using IMDb movie reviews data for training. The final deployed model uses **Logistic Regression** for robust performance and is accessible via an interactive **Streamlit web app**. --- ## ğŸ§© Dataset The project uses the **IMDb Movie Reviews Dataset**: - **Source:** [Kaggle](https://www.kaggle.com/datasets/mantri7/imdb-movie-reviews-dataset) - **Initial file used:** train_data (1).csv - **Cleaned & preprocessed dataset:** reddit_preprocessing.csv ### ğŸ§¹ Data Preprocessing Steps 1. **Load Dataset**
python
df = pd.read_csv('train_data (1).csv')


ai tuko jmn kore likco thik tmn kore bad baki puro ta o same vabe likhe daw

Clean Text Using NLP Preprocessing

Remove HTML tags

Remove non-alphabetic characters

Convert to lowercase

Remove stopwords

Save Cleaned Dataset
The cleaned dataset is saved as reddit_preprocessing.csv for further experiments.

Exploratory Data Analysis (EDA)

Understand class distributions

Explore text patterns and word frequencies

ğŸ§ª Experiments

The project follows a systematic approach to model evaluation, covering multiple experiments:

1ï¸âƒ£ Bag-of-Words & TF-IDF Experiments

Notebooks:

3_experiment_2_bow_tfidf_1.ipynb

3_experiment_2_bow_tfidf.ipynb

4_experiment_3_tfidf_(1,3)_max_features.ipynb

5_experiment_4_handling_imbalanced_data.ipynb

Best Result (Logistic Regression):

Accuracy: 0.8940

Precision: 0.8940

Recall: 0.8940

F1-score: 0.8940

Best Parameters: {'solver': 'lbfgs', 'max_iter': 300, 'C': 10}

2ï¸âƒ£ Naive Bayes with Hyperparameter Tuning

Notebook: 6_experiment_5_Naive Bayes_with_hpt.ipynb

Result:

Accuracy: 0.8711

Precision: 0.8713

Recall: 0.8711

F1-score: 0.8711

3ï¸âƒ£ XGBoost

Notebook: 7_experiment_5_xgboost_with_hpt.ipynb

Result:

Best Accuracy: 0.8514

Best Parameters: {'n_estimators': 150, 'learning_rate': 0.09, 'max_depth': 9, ...}

4ï¸âƒ£ LightGBM

Notebook: 7_experiment_6_lightgbm_detailed_hpt.ipynb

Result: Accuracy = 0.8767

5ï¸âƒ£ Random Forest

Notebook: 7_experiment_6_RandomForest_detailed_hpt.ipynb

Result: Accuracy = 0.8554

6ï¸âƒ£ Deep Learning (LSTM)

Notebook: 7_experiment_6_Using_Deep_Learning_LSTM_with_hptn.ipynb

Result:

Accuracy: 0.8573

Precision: 0.8732

Recall: 0.8365

F1-score: 0.8545

7ï¸âƒ£ Stacking Classifier

Notebook: 8_Staking.ipynb

Base learners: XGBoost, LightGBM, Random Forest, Naive Bayes, Logistic Regression

Result: Accuracy = 0.8980

ğŸ† Model Selection & Deployment

After thorough experiments, Logistic Regression and Stacking gave the best results. For simplicity and reliability, Logistic Regression was selected for deployment.

Saved Models

logreg_model.pkl

vectorizer_model.pkl

Web App Deployment

Framework: Streamlit

Local URL: http://localhost:8501

Features:

User-friendly interface

Real-time sentiment prediction

Displays confidence percentage

Supports text input via text area

ğŸ“ Repository Structure
/Task-sentiment-analyzer
â”‚
â”œâ”€â”€ /Notebook                   # All Jupyter notebooks
â”‚   â”œâ”€â”€ 1_data_preprocessing.ipynb
â”‚   â”œâ”€â”€ 3_experiment_2_bow_tfidf.ipynb
â”‚   â”œâ”€â”€ 3_experiment_2_bow_tfidf_1.ipynb
â”‚   â”œâ”€â”€ 4_experiment_3_tfidf_(1,3)_max_features.ipynb
â”‚   â”œâ”€â”€ 5_experiment_4_handling_imbalanced_data.ipynb
â”‚   â”œâ”€â”€ 6_experiment_5_Naive Bayes_with_hpt.ipynb
â”‚   â”œâ”€â”€ 7_experiment_5_xgboost_with_hpt.ipynb
â”‚   â”œâ”€â”€ 7_experiment_6_lightgbm_detailed_hpt.ipynb
â”‚   â”œâ”€â”€ 7_experiment_6_RandomForest_detailed_hpt.ipynb
â”‚   â”œâ”€â”€ 7_experiment_6_Using_Deep_Learning_LSTM_with_hptn.ipynb
â”‚   â””â”€â”€ 8_Staking.ipynb
â”‚
â”œâ”€â”€ /Notebook/Models             # Saved trained models
â”‚   â”œâ”€â”€ logreg_model.pkl
â”‚   â”œâ”€â”€ stacking_model.pkl
â”‚   â””â”€â”€ vectorizer_model.pkl
â”‚
â”œâ”€â”€ reddit_preprocessing.csv     # Cleaned dataset
â”œâ”€â”€ app.py                       # Streamlit deployment code
â”œâ”€â”€ requirements.txt             # Dependencies
â””â”€â”€ README.md                    # Project documentation

âš¡ How to Use
1ï¸âƒ£ Clone the repository
git clone https://github.com/Latif1218/Task-sentiment-analyzer.git
cd Task-sentiment-analyzer

2ï¸âƒ£ Create a virtual environment and install dependencies
python -m venv env
.\env\Scripts\activate  # Windows
pip install -r requirements.txt

3ï¸âƒ£ Run the Streamlit app
streamlit run app.py


Open your browser at http://localhost:8501 to access the sentiment analyzer.

ğŸ“Š Key Takeaways

Preprocessing and EDA are critical for robust NLP modeling.

Logistic Regression with TF-IDF achieved the best balance of simplicity and accuracy.

Stacking multiple models can slightly improve performance but adds complexity.

The deployed Streamlit app provides real-time sentiment analysis with confidence scoring.

ğŸ§‘â€ğŸ’» Contributing

Contributions are welcome! Feel free to fork the repository, make changes, and submit pull requests.

ğŸ“„ License

This project is licensed under the MIT License.


âœ… This version is **fully ready to copy** into your `README.md`. It will **render nicely on GitHub** with headings, bullets, code blocks, and proper formatting.  

If you want, I can also **add a separate small section for text cleaning with a mini code snippet example**, so HTML removal, lowercase conversion, and stopword removal are visually highlighted for extra clarity.  

Do you want me to do that?

puro ak shate lune by line na akbare akshate